{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solution_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3yH/Dti4TRvbSYUD2AZpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anirud-Mohan/Machine-Learnning/blob/main/Solution_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bayesian Linear Regression from scratch with BlackJAX**"
      ],
      "metadata": {
        "id": "5Qzg48pGTUdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4MJPva5RD7oW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad31050-89d5-4d1f-a2cb-8f149b8087bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "# Randomness for the entire program\n",
        "master_key=7 # Decides the output change d\n",
        "key = jax.random.PRNGKey(master_key)\n",
        "subkey, key = jax.random.split(key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instances=30; # Number of data_point instances \n",
        "\n",
        "# The data_point samples are declared global\n",
        "global X, Y, Noise_var\n",
        "\n",
        "# Limits of the input data_pints\n",
        "Lower_limit=0; \n",
        "Upper_limit=1;\n",
        "\n",
        "True_bias=1\n",
        "True_slope=1\n",
        "Noise_var=0.02\n",
        "\n",
        "# The input data_points are sampled uniformly in the interval specified by the limits\n",
        "X=jax.random.uniform(subkey, [instances], minval=Lower_limit, maxval=Upper_limit)\n",
        "subkey, key = jax.random.split(key)\n",
        "\n",
        "# Noise, 'N' is generated\n",
        "N=jax.numpy.sqrt(Noise_var) * jax.random.normal(subkey, [instances])\n",
        "subkey, key = jax.random.split(key)\n",
        "\n",
        "# Output data_points are generated as described in the text above.\n",
        "Y = True_slope*X  +True_bias + N"
      ],
      "metadata": {
        "id": "MSRndTqRTgoe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def posterior(Est_bias, Est_slope):\n",
        "  # Data_points and Noise variance to be read\n",
        "  global X, Y, Noise_var\n",
        "\n",
        "  # The likelihood and hence the posterior are computed in a 'proportional' manner here.\n",
        "  # The value returned is the exponential of the sum squared distances\n",
        "  sum=0\n",
        "  for i in range(jax.numpy.size(X)):\n",
        "    sum = sum-((Y[i]-X[i]*Est_slope-Est_bias) * (Y[i]-X[i]*Est_slope-Est_bias)/(2*Noise_var))\n",
        "  return jax.numpy.exp(sum)"
      ],
      "metadata": {
        "id": "35e3KToETzd9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples of the posterior along each parameter axis\n",
        "No_of_posterior_points=20\n",
        "\n",
        "# Parameter limits of the posterior distribution plot\n",
        "lower_limit=0.75\n",
        "upper_limit=1.25\n",
        "\n",
        "# This variable stores the posterior values at the sample positions\n",
        "Posterior_values = jax.numpy.zeros([No_of_posterior_points, No_of_posterior_points])\n",
        "# This variable stores the bias values at the sample positions\n",
        "Bias_points = jax.numpy.zeros([No_of_posterior_points, No_of_posterior_points])\n",
        "# This variable stores the slope values at the sample positions\n",
        "Slope_points = jax.numpy.zeros([No_of_posterior_points, No_of_posterior_points])\n",
        "\n",
        "# SAMPLING THE POSTERIOR HERE\n",
        "Current_posterior_max=-1\n",
        "for i in range(No_of_posterior_points): # This loop changes bias values\n",
        "  for j in range(No_of_posterior_points): # This loop changes slope values\n",
        "\n",
        "    Bias_points = Bias_points.at[i,j].set(lower_limit + (upper_limit-lower_limit)*i/(No_of_posterior_points-1) )\n",
        "    Slope_points = Slope_points.at[i,j].set(lower_limit + (upper_limit-lower_limit)*j/(No_of_posterior_points-1) )    \n",
        "    Posterior_values = Posterior_values.at[i,j].set(posterior(Bias_points[i,j], Slope_points[i,j]))\n",
        "\n",
        "    # Find the highest posterior value and the corresponding parameter values\n",
        "    if(Posterior_values[i,j] > Current_posterior_max):\n",
        "      Current_posterior_max = Posterior_values[i,j]\n",
        "      Bias_prediction = Bias_points[i,j]\n",
        "      Slope_prediction = Slope_points[i,j]\n",
        "\n",
        "# Plotting the sampled posterior here as a color map\n",
        "fig, ax = plt.subplots()\n",
        "ax.pcolormesh(Bias_points, Slope_points, Posterior_values)\n",
        "ax.scatter(True_bias, True_slope, s=40, c='white', marker='x', label='True parameter values')\n",
        "ax.scatter(Bias_prediction, Slope_prediction, s=20, c='red', label='Best parameter fit')\n",
        "plt.title(\"Posterior magnitude plot\")\n",
        "plt.xlabel(\"Bias\")\n",
        "plt.ylabel(\"Slope\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "CsxzdWLtT10I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the posterior PDF\n",
        "Posterior_values = Posterior_values/jax.numpy.sum(Posterior_values)\n",
        "\n",
        "# Initializing the posterior CDF\n",
        "Posterior_CDF = jax.numpy.zeros([No_of_posterior_points,No_of_posterior_points])\n",
        "\n",
        "# Creating the approximate posterior CDF from the sampled PDF\n",
        "sum=0\n",
        "for i in range(No_of_posterior_points):\n",
        "  for j in range(No_of_posterior_points):\n",
        "    sum = sum+Posterior_values[i,j];\n",
        "    Posterior_CDF = Posterior_CDF.at[i,j].set(sum)"
      ],
      "metadata": {
        "id": "dPFf6BLzUUsk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "No_of_parameter_samples=18; # Number of posterior samples\n",
        "plot_points=jax.numpy.linspace(Lower_limit, Upper_limit, 100) # Plotting points range\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for instance in range(No_of_parameter_samples):\n",
        "  # Sampling the uniform random variable\n",
        "  CDF_value = jax.random.uniform(subkey, [1], minval=0, maxval=1)\n",
        "  subkey, key = jax.random.split(key)\n",
        "\n",
        "  # Converting the uniform random variable samples to posterior samples\n",
        "  found=0\n",
        "  for i in range(No_of_posterior_points):\n",
        "    for j in range(No_of_posterior_points):\n",
        "      if(Posterior_CDF[i,j] > CDF_value):\n",
        "        found=1;\n",
        "        Bias_sample = Bias_points[i,j];\n",
        "        Slope_sample = Slope_points[i,j];\n",
        "        break\n",
        "    if(found == 1):\n",
        "        break\n",
        "  \n",
        "  # Plotting the posterior samples\n",
        "  ax.plot(plot_points, Bias_sample+(Slope_sample*plot_points), color=\"orange\", linewidth=5, alpha=0.15)\n",
        "ax.plot(plot_points, Bias_sample+(Slope_sample*plot_points), color=\"orange\", linewidth=5, alpha=0.15, label='Posterior_samples')  \n",
        "\n",
        "# Plotting the predictive mean(ML on parameters)\n",
        "ax.plot(plot_points, Bias_prediction+Slope_prediction*plot_points, color=\"black\", linewidth=2, label='Predictive mean')\n",
        "\n",
        "# Plotting the data points\n",
        "plt.scatter(X, Y, s=10, label='Data_points')\n",
        "plt.legend()\n",
        "plt.title(\"Data_point fitting\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\");"
      ],
      "metadata": {
        "id": "HNs3bixOUX01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}